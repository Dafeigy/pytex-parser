{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parse_tex(file, config):\n",
    "    # rule = re.compile(r'\\\\begin{equation}(.*?)\\\\end{equation}',re.S)\n",
    "    # with open(file, 'rb') as f:\n",
    "    #     content = f.read().decode('utf-8')\n",
    "    #     content = content.replace('\\n','')\n",
    "    #     results = rule.findall(content)\n",
    "    # return results\n",
    "    pass\n",
    "\n",
    "def remove_annotations(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    no_annotation = ''.join([line for line in lines if line.strip() != \"\" and not line.startswith(\"%\")])\n",
    "    return no_annotation\n",
    "\n",
    "def remove_environment(content, environment_name):\n",
    "\n",
    "    pattern = r'\\\\begin{' + environment_name + r'}.*?\\\\end{' + environment_name + r'}'\n",
    "    modified_content = re.sub(pattern, '', content, flags=re.DOTALL)\n",
    "    return modified_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_annotations = remove_annotations(r\"test-folder\\2010.01815\\main.tex\")\n",
    "no_environments = remove_environment(no_annotations, \"equation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_pattern = r'\\\\section{(.*?)}'\n",
    "section_names = re.findall(section_pattern, no_environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\\\documentclass[journal]{IEEEtran}\\n\\\\usepackage{amsmath,graphicx,url,times,hyperref}\\n\\\\usepackage{amssymb}\\n\\\\usepackage{mathrsfs}\\n\\\\usepackage{booktabs}\\n\\\\usepackage[T1]{fontenc}\\n\\\\usepackage{algorithm}\\n\\\\usepackage{algpseudocode}\\n\\\\usepackage{textcomp}\\n\\\\usepackage[usenames, dvipsnames]{color}\\n\\\\usepackage{booktabs}\\n\\\\def\\\\x{{\\\\mathbf x}}\\n\\\\def\\\\L{{\\\\cal L}}\\n\\\\newcommand{\\\\qk}[1] {{\\\\color{black} #1}}\\n\\\\usepackage{multirow}\\n\\\\ifCLASSINFOpdf\\n  % \\\\usepackage[pdftex]{graphicx}\\n  % declare the path(s) where your graphic files are\\n  % \\\\graphicspath{{../pdf/}{../jpeg/}}\\n  % and their extensions so you won't have to specify these with\\n  % every instance of \\\\includegraphics\\n  % \\\\DeclareGraphicsExtensions{.pdf,.jpeg,.png}\\n\\\\else\\n  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx\\n  % will default to the driver specified in the system graphics.cfg if no\\n  % driver is specified.\\n  % \\\\usepackage[dvips]{graphicx}\\n  % declare the path(s) where your graphic files are\\n  % \\\\graphicspath{{../eps/}}\\n  % and their extensions so you won't have to specify these with\\n  % every instance of \\\\includegraphics\\n  % \\\\DeclareGraphicsExtensions{.eps}\\n\\\\fi\\n\\\\hyphenation{op-tical net-works semi-conduc-tor}\\n\\\\begin{document}\\n\\\\title{{\\\\huge High-resolution Piano Transcription with Pedals by Regressing Onset and Offset Times}}\\n\\\\author{Qiuqiang Kong, Bochen Li, Xuchen Song, Yuan Wan, Yuxuan Wang\\\\thanks{Q. Kong, B. Li, X. Song, Y. Wan, Y. Wang are with ByteDance. (e-mail: kongqiuqiang@bytedance.com; bochenli@bytedance.com; xuchen.song@bytedance.com, wanyuan.0626@bytedance.com, wangyuxuan.11@bytedance.com). \\\\textit{(Qiuqiang Kong is first and corresponding author.)}}}\\n\\\\maketitle\\n\\\\begin{abstract}\\nAutomatic music transcription (AMT) is the task of transcribing audio recordings into symbolic representations. Recently, neural network-based methods have been applied to AMT, and have achieved state-of-the-art results. However, many previous systems only detect the onset and offset of notes frame-wise, so the transcription resolution is limited to the frame hop size. There is a lack of research on using different strategies to encode onset and offset targets for training. In addition, previous AMT systems are sensitive to the misaligned onset and offset labels of audio recordings. Furthermore, there are limited researches on sustain pedal transcription on large-scale datasets. In this article, we propose a high-resolution AMT system trained by regressing precise onset and offset times of piano notes. At inference, we propose an algorithm to analytically calculate the precise onset and offset times of piano notes and pedal events. We show that our AMT system is robust to the misaligned onset and offset labels compared to previous systems. Our proposed system achieves an onset F1 of 96.72\\\\% on the MAESTRO dataset, outperforming previous onsets and frames system of 94.80\\\\%. Our system achieves a pedal onset F1 score of 91.86\\\\%, which is the first benchmark result on the MAESTRO dataset. We have released the source code and checkpoints of our work at \\\\url{https://github.com/bytedance/piano\\\\_transcription}.\\n\\\\end{abstract}\\n\\\\begin{IEEEkeywords}\\nPiano transcription, pedal transcription, high-resolution.\\n\\\\end{IEEEkeywords}\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_content = [no_environments]\n",
    "for section_name in section_names:\n",
    "    temp = section_content[-1].split(\"\\\\section{\"+section_name+\"}\")\n",
    "    section_content[-1] = temp[0]\n",
    "    section_content.append(temp[1])\n",
    "section_content.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsection_pattern = r\"\\\\subsection{(.*?)}\"\n",
    "subsection_list = [re.findall(subsection_pattern, each) for each in section_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsections = []\n",
    "for index, keywords in enumerate(subsection_list):\n",
    "    subsection_content = [section_content[index]]\n",
    "    for keyword in keywords:\n",
    "        temp = subsection_content[-1].split(\"\\\\subsection{\" + keyword + \"}\")\n",
    "        subsection_content[-1] = temp[0]\n",
    "        subsection_content.append(temp[1])\n",
    "    subsection_content.pop(0)\n",
    "    subsections.append(subsection_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
